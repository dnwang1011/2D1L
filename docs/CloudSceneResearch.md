Building a Scroll-Driven Volumetric Cloud Hero Section

1. React Three Fiber / Three.js Cloud Techniques & Demos
	•	Ray-Marched Volumetric Cloud Examples: Several R3F developers have created raymarching cloud demos. For instance, Anderson Mancini adapted Three.js’s volumetric cloud example (which uses a 3D noise texture for density) into an R3F component ￼. Faraz Shaikh’s open-source three-volumetric-clouds implements Guerrilla Games’ cloud rendering techniques (e.g. Perlin-Worley noise, adaptive ray-marching, multi-scattering) in Three.js ￼. These examples showcase true volumetric clouds with deep parallax and realistic lighting, closely emulating the Cartier Journey’s soft cloudscape aesthetic.
	•	Dedicated Cloud Libraries: Specialized libraries can jump-start development. Notably, the @takram/three-clouds package offers a high-quality volumetric cloud implementation for Three.js/R3F ￼. It supports Beer-Lambert cloud shadows, temporal upscaling for performance, crepuscular rays (“god rays”), and ground haze ￼ – features useful for golden-hour skies. This library integrates with R3F (via Clouds and Atmosphere components) and uses postprocessing (EffectComposer) to layer volumetric clouds with sky atmosphere ￼ ￼.
	•	Noise-Based Plane Stacking: A simpler approach uses multiple semi-transparent cloud layers or billboards with noise textures. For example, Drei’s built-in <Cloud> component instantiates billboards with a fluffy cloud texture and always faces them to the camera ￼. This is an inexpensive technique that can still achieve soft, volumetric-looking clouds when layers are stacked with slight height differences (creating parallax) ￼. Mr.doob’s classic cloud demo and its modern implementations use dozens of textured planes (merged or instanced) to form a cloud volume ￼. By using seamless noise textures on each plane and scrolling them over time, one can simulate moving, ethereal cloud banks ￼.
	•	R3F + Scroll Interaction Demos: Look for open-source R3F demos that combine 3D clouds with scroll or camera movement. For example, 14islands’ r3f-scroll-rig template shows how to sync Three.js scenes with scroll, which can be applied to a cloud fly-through hero section. It keeps a single WebGL canvas for the entire page and allows DOM elements to “mount” 3D content at scroll positions ￼ ￼. By tying cloud layer positions or camera altitude to the scroll progress (using hooks like useFrame or Drei’s useScroll), you can create an interactive journey “through the clouds” as in the Cartier intro.

2. GLSL Shader Code Snippets & Resources
	•	Noise-Driven Cloud Density: Volumetric cloud shaders rely on procedural noise to define density. A common choice is Perlin-Worley noise, which combines Perlin (smooth) and Worley (cellular) noise to create fluffy cloud shapes ￼. Many cloud shaders use 3D fractal noise (FBM – fractal Brownian motion) – layering multiple octaves of noise for detail ￼. For example, Guerrero et al.’s cloud shader on Shadertoy (3dVXDc) generates tileable Perlin-Worley noise suitable for a 3D density texture ￼. In GLSL, you might sample a 3D noise texture with coordinates (x, y, z + time*speed) to animate the cloud formation slowly. Resource: Maxime Heckel’s “Real-time Cloudscapes” blog post provides a noise function for volumetric clouds that samples a precomputed 2D noise texture with offsets for each slice ￼ ￼, effectively emulating a 3D noise in the shader.
	•	Soft Edges & Alpha Feathering: To achieve those dreamy, soft cloud boundaries, you can apply smoothing functions to the density field. In shader code, this means using a smoothstep on density near the threshold between cloud and sky. For instance, after computing density, one might do alpha = smoothstep(density, threshold - falloff, threshold + falloff) to feather the edges. In practice, some artists even combine a solid shape with volumetrics: “start with a solid object in the center… then add volumetric highlights to the outside” for a realistic dense core and soft outline ￼. If using billboard cloud sprites, ensure the cloud texture itself has blurred edges (or use a radial alpha gradient via Fresnel in the fragment shader) so that when sprites overlap, the cloud appears fluffy and not cut-out.
	•	Light Scattering & Phase Functions: Realistic golden-hour clouds glow because of anisotropic scattering – more light scatters forward through cloud droplets than back. In GLSL, a common approximation is the Henyey–Greenstein phase function, which takes a g-factor (e.g. 0.8 for forward-scattering) ￼ ￼. Maxime Heckel notes that almost all physically-based volumetric cloud shaders use Henyey–Greenstein to weight light contributions ￼ ￼. A snippet for HG in GLSL looks like: float HenyeyGreenstein(float g, float mu){ float gg = g*g; return (1.0/(4.0*PI))*((1.0-gg)/pow(1.0+gg-2.0*g*mu, 1.5)); } ￼, where mu = dot(viewDir, lightDir). You’d multiply your sample’s light intensity by this phase factor to get that soft glow around the sun. Some shaders also add a simple Mie scattering lobe for the glowing cloud edges at sunset, or an exponential falloff to simulate multiple scattering (e.g. adding a constant ambient term to clouds). Resources: Sebastien Hillaire’s SIGGRAPH talk on Frostbite atmospheric scattering and Simon Dev’s “How Big Budget Games Render Clouds” ￼ dive deeper into these lighting models.
	•	God Rays and Light Shafts: If the design calls for sunbeams breaking through clouds, you can approximate this via post-processing. One technique is a crepuscular rays shader that radial-blurs bright areas (the sun) to create streaks. Three.js has a god-rays pass in its examples, or you can implement a radial blur in the fragment shader sampling along the sun direction. The Takram cloud library builds this in (light shafts are an option) ￼. For added realism, animate the shafts subtly (noise or time variation) so rays appear to shimmer as cloud density shifts.
	•	Time-Based Cloud Animation: To keep clouds dynamic, gently evolve the noise over time. A simple GLSL trick is to treat time as a fourth noise dimension (e.g. use 3D noise with a moving “W” coordinate, or continuously translate the noise sample position). For example, moving the sampling coordinate slightly each frame: vec3 samplePos = p + vec3(windX, windY, windZ)*uTime will cause the cloud pattern to drift ￼ ￼. The movement should be slow and subtle – think of high-altitude clouds barely shifting during the scroll interaction. Low-frequency noise can be morphed over time by interpolating between two sets of noise values (morphing one noise field into another to simulate clouds forming/dissipating) ￼. Resources: Shadertoy has many cloud animations demonstrating 4D noise (e.g. “Volumetric Cloud Marching” uses time-varying Worley noise). Also, check the Book of Shaders chapters on noise for ideas on moving and looping noise patterns.

3. Seamless Noise Textures for Clouds
	•	Tileable 3D Noise: Using a 3D texture for cloud density can be more efficient than computing FBM in the fragment shader. However, a large 3D texture can be heavy, so a balance is needed. A 128×128×128 tileable noise volume (≈2 MB) is a proven choice ￼ – it’s small enough for web and can represent a few layers of fractal detail. You can generate such a texture by combining noise functions (Perlin + Worley) offline, or even in-browser at startup. Guerrilla’s Nubis system did this: generate a tileable 3D noise, then repeat it at different scales in-shader to add detail instead of using a bigger texture ￼. If you cannot load a 3D texture, an alternative is to pack slices of 3D noise into a 2D texture ￼ ￼. Each row of the image can store a Z-slice of noise; a custom shader function then samples this 2D noise atlas with (x, y, z) coordinates to reconstruct the noise value. Thefrontdev’s article demonstrates slicing a 3D noise into a 2D DataTexture and how to index it in GLSL ￼ ￼. This workaround leverages standard WebGL2 textures to simulate 3D noise.
	•	Seamless 2D Noise for Layers: If you use layered cloud planes or need 2D noise for clouds, ensure it’s seamless (tileable in both axes) to avoid visible seams when moving or wrapping textures. You can generate seamless Perlin or Simplex noise using domain warping or by sampling a 3D noise on a 2D torus. There are free resources like OpenGameArt’s noise texture packs containing hundreds of tileable noise images ￼ (Perlin, ridged, etc.) at various resolutions (128×128, 256×256). These can be used as alpha maps for cloud sprites or as starting points for volumetric slicing. Another option is procedural noise libraries in JS: for example, you could use a library like simplex-noise or fast-noise-lite to generate a tileable 2D noise on the CPU, then upload it to a texture. Keep in mind JPG/PNG images might introduce banding – prefer storing noise in a PNG or as raw float DataTexture for best quality.
	•	3D Noise Generation Tools: For more complex cloud shapes, you might combine multiple noise types. Worley (voronoi) noise gives billowy cloud outlines, while Perlin gives softness. Tools like NoiseMaker or 3D noise generation scripts can produce tileable 3D Worley or Perlin noise which you then import as .dds or .ktx volume textures (with compression for GPU). You can also leverage 3D software: e.g., use Blender’s procedural textures to bake a 3D noise volume or a flipbook of noise. Ensure any noise texture (2D or 3D) you use is tileable and seamlessly wraps, so that as you translate or loop it in the shader, there are no popping discontinuities.
	•	Blue Noise for Dithering: Blue noise isn’t used for the cloud shape itself, but it’s extremely useful for improving visual quality (see Optimization section). Consider including a small blue noise texture (e.g. 256² or 512²) which is tileable ￼. Blue noise has a neutral, evenly-distributed pattern that, when used to dither opacity or sample positions, minimizes perceptible patterns. You can get free blue noise textures (2D, 3D, even 4D) from the Moments in Graphics repository ￼. In practice, you might use a 4D blue noise (indexed by frame) to jitter your raymarch sample points slightly each frame, creating a flicker-free, soft result after temporal accumulation.

4. Color Palettes & Gradient References

The target color palette is a dreamy golden-hour sky with soft golds, peaches, and hints of lavender. Based on the description and similar scenes, here is a curated palette of hex colors (with suggested usage):
	•	Jasmine Gold – #FFDA82 ￼ (a luminous soft gold, for sunlit cloud highlights and warm light scattering).
	•	Light Crimson (Peach Pink) – #EB6A8C ￼ (a peachy pink glow, for cloud body tint and mid-sky hues).
	•	Crayola Tan (Warm Apricot) – #DE956B ￼ (a deeper warm peach, use for denser cloud areas or low-sun horizon glow).
	•	Old Lavender – #6E5A7B ￼ (a muted lavender-purple, for the high sky or underside of clouds away from sun).
	•	Champagne Pink – #F7E7CE ￼ (very light peachy-cream, to blend clouds into the sky or as the fog/haze color near horizon).

Using these colors, you can create rich gradients. For example, a sky background CSS linear-gradient might go from a pale peach at the horizon to lavender at the zenith. For instance:

/* Golden hour sky gradient */
background: linear-gradient(180deg, #FFDA82 0%, #EB6A8C 50%, #6E5A7B 100%);

This transitions from soft gold (#FFDA82) through peach-pink (#EB6A8C) to dusk purple (#6E5A7B). Another variant could add an even lighter tint at the very bottom (near-white or #FFF5E1) to mimic the sun near the horizon. You can also use these hex codes in Three.js materials and lights – for example, set the fog color to a lavender (#6E5A7B) and the cloud material color to peach (#EB6A8C) so that distance fog and cloud color blend naturally at dusk. The combination of warm highlights and cool purples will give that rose-gold sky effect that defined the Cartier scene.

5. Performance Optimization Tips for Volumetric Clouds

Volumetric clouds can be expensive, so it’s crucial to optimize for WebGL2 and varying device capabilities:
	•	Dynamic Resolution & Upscaling: A key strategy is rendering the cloud volume at a lower resolution and upscaling it. You can ray-march clouds to an offscreen buffer at, say, half or quarter resolution, then upscale with filtering. The Takram cloud library implements temporal upscaling (accumulating detail over frames) ￼ for this purpose. This leverages the idea that clouds don’t need full resolution every frame if blended over time. As forum experts suggest, you can “upscale a lot, rendering in a lower resolution” for clouds ￼ – especially if combined with motion blur or jitter to mask the pixelation.
	•	Adaptive Sampling: Reducing the number of ray-march steps is the main way to gain performance. The trick is to do it adaptively:
	•	Use a logarithmic depth step distribution for raymarch samples ￼. Take more samples when the ray is near the camera and fewer for faraway portions of the cloud (since distant detail is less visible). This balances detail across depth and prevents over-sampling close vs. far ￼ ￼.
	•	Implement early ray termination – as you accumulate density, once it exceeds a threshold (cloud becomes opaque), break out of the loop ￼. No need to march through a cloud’s interior once it’s fully opaque to the eye.
	•	Limit shadow ray distance: When sampling secondary rays toward the light (for cloud self-shadowing), only march a fixed distance (e.g. a few hundred meters in scene units) ￼. Distant portions of the cloud won’t cast noticeable shadows and can be ignored to save work. Also reduce the number of light-samples for optically thin parts of the cloud ￼ (if a sample’s density is low, don’t waste many shadow steps on it).
	•	Use LOD for noise: Sample fewer octaves of noise for far clouds. One technique is to use a high-detail noise for nearby/cloud edges, but for clouds on the horizon use a cheaper, more blurred noise. Fade between these levels of detail smoothly with distance to avoid pops ￼.
	•	Dithered Sampling: When you cut down samples, banding artifacts (discrete layers) can appear. To counter this, introduce a small random jitter to sample positions (stochastic sampling). It’s recommended to use blue noise for this jitter pattern ￼. Blue noise has minimal clumping, so even with few samples the distribution looks uniform. By jittering the ray step positions per pixel (or frame) with a blue noise texture, you turn banding into a fine-grained dithering which can then be filtered out.
	•	Post-process Smoothing: Given dithering, apply a gentle blur to the cloud render. An edge-preserving Kawase blur is a popular choice to smooth out noise without erasing cloud shapes ￼. Kawase blur is fast and can be done in a couple of passes. Use the blue noise again during the blur to avoid introducing new patterns ￼. Also weight the blur such that it blurs flat areas more than high-contrast edges (preserve details like cloud contours) ￼. The result is a soft look, hiding sampling artifacts. SimonDev’s bloom tutorial explains Kawase blur in detail ￼.
	•	Quality Scalability: Design multiple quality settings for the cloud effect, especially for mobile vs desktop. For example, LOD downgrade: on low-end devices use fewer raymarch steps, fewer FBM octaves, and no secondary shadow rays (just ambient lighting). You can also switch to a completely different technique if needed – e.g. fall back to a static skybox or a plane with cloud texture on very slow devices. By checking the device performance (use navigator.hardwareConcurrency or rough fps detection), you can dynamically choose a simplified cloud shader or reduce the resolution/density of clouds. The goal is to degrade gracefully: maintain the overall aesthetic (color and feel) of the clouds, but sacrifice fine details and volumetric depth on low specs rather than dropping frames.

6. R3F Specific Implementation Patterns (Scroll & Shaders in Next.js)

Building this in React Three Fiber within a Next.js app introduces some patterns to manage complexity:
	•	Persistent Canvas & Layout: To integrate a fullscreen WebGL scene with scroll-driven DOM content, consider keeping one global <Canvas> that spans the viewport (e.g. fixed positioning). In Next.js, you can include this canvas in _app.js or a layout so it doesn’t remount on page changes. The 14islands r3f-scroll-rig uses a <GlobalCanvas> that stays active between pages ￼. This approach avoids re-creating Three.js contexts and allows WebGL content to synchronize with page scroll.
	•	Scroll-Linking Techniques: R3F provides helpers like <ScrollControls> and the useScroll() hook (from Drei) that create a scroll container and normalize scroll progress for you. This is great if your cloud hero section is one part of a longer page: you can drive cloud animation or camera movement by the scroll offset. For more advanced scenarios (scrolling multiple sections with interleaved HTML and WebGL), libraries like the scroll-rig use “proxy” HTML elements and a tracker that updates 3D object positions to match scroll ￼. In simpler terms, you can also just use a React useEffect on the window scroll event (or a scroll library like Lenis/GSAP) to update R3F state. For example, on scroll, adjust the camera’s position or rotation slightly (for parallax) or update a uniform like cloudOffset that translates your noise texture coordinates. Using R3F’s useFrame, you can smoothly interpolate towards scroll-driven targets each frame (for instance, useFrame(() => camera.position.y = lerp(camera.position.y, scrollY * factor, 0.1))).
	•	Organizing Shader Code in R3F: When using custom shaders in R3F, you’ll likely use <shaderMaterial> or extend to create your material class. Keep GLSL code in separate .glsl.js files or template literals for clarity. Use useMemo to create shader materials or large data textures so that they are not re-created on every render. For example, generating a noise DataTexture for clouds can be done once and stored with useMemo() ￼, and then you pass it to your ShaderMaterial uniform. This ensures expensive prep (like filling noise arrays) runs only once. Manage your shader uniforms with React state or refs – R3F allows you to attach uniforms easily. You can keep a ref to the material (useRef()), then update material.current.uniforms.uTime.value inside useFrame for animation.
	•	Performance and Layering: R3F’s declarative nature is convenient, but be mindful of performance. Use Canvas props like dpr={[1, 2]} to limit device pixel ratio on high DPI screens (saves fill rate), and <Perf /> from Drei during development to monitor frame rate. To optimize layering, you can leverage Three.js layers or multiple scenes if needed: for instance, render the volumetric clouds in the background and your foreground content separately. One approach is using the <EffectComposer> with a RenderPass for clouds at lower resolution, then a RenderPass for the rest of the scene – effectively layering without multiple canvases. Within R3F, you might simply draw your cloud mesh first (they’ll naturally appear behind if depth is setup) and mark them with material.depthWrite=false if they should blend additively with the sky. Using fog in the scene that matches your sky colors can also help merge the cloud edges with the background color smoothly.
	•	Hooks and Best Practices: Use R3F hooks like useFrame to handle animation state (scroll, time, mouse, etc) each frame, but avoid heavy calculations inside it – delegate expensive work to GLSL or do it once in init. useMemo and useCallback are your friends to prevent re-calculating geometry or textures on every render. Also consider using React suspense/lazy to load any assets (like noise textures or models) so that your app doesn’t block the UI thread. If your clouds use large textures or lots of instanced sprites, use R3F’s <Preload /> and <Instances> to efficiently manage them. Separating the cloud logic into a custom <CloudScene> component that takes props (like lighting conditions or scroll position) can keep your code modular. This also makes it easier to toggle the whole cloud layer off for performance or debugging.

7. Toolkits or Libraries (Beyond Drei) for Shaders & Atmosphere
	•	Shader Composition Libraries: Writing complex GLSL by hand can be error-prone. Libraries like shader-composer (NPM package shader-composer) provide a functional API to build shaders in JavaScript ￼. This lets you construct noise, combine shader nodes, and produce a Three.js ShaderMaterial without directly writing GLSL for every step. It’s great for prototyping procedural effects – for example, you can create a noise node, a distortion node, etc., and it handles merging them. Another tool is glslify (with packages like glsl-noise ￼ and others) which allows you to import common shader functions (Perlin noise, FBM, etc.) as modules. This can simplify adding, say, Worley noise – you #pragma glslify: worley = require('glsl-worley') and then call worley(vec3) in your shader.
	•	Node-Based Shader Editors: If you prefer a visual approach, NodeToy is a web-based shader graph editor that exports directly to Three.js ￼. You can design the cloud material by connecting nodes (noise, gradient, lighting, etc.) and then integrate the generated shader code into your R3F project. This is helpful for iterating on the look – for example, you could interactively tweak a noise distortion or color gradient and see the results, then bring that shader into React. Three.js also has an official Nodes system (MaterialNodes/NodeMaterial) which is evolving; it could be used to set up cloud shaders via a node API, though documentation is still catching up.
	•	Atmospheric Sky Libraries: To complement clouds, you might use a sky/atmosphere library. @takram/three-atmosphere is one (goes with three-clouds) that provides physical sky and aerial perspective fog ￼. There’s also Drei’s <Sky> component (for a simple gradient sky dome) – though for golden hour you might want a custom shader to get those rich colors. For sun shafts and bloom, consider the postprocessing library (react-postprocessing for R3F) which offers effects like Bloom, GodRays, etc., that can be stacked. For example, adding a subtle BloomPass can amplify the brightness of the sun-lit cloud edges.
	•	Procedural Texture Generators: Outside of Three.js, tools like NoiseTool (by shader artists) can generate tileable noise images which you can import. Alternatively, FastNoise Lite (WASM/JS library) can generate 3D noise on the fly; while not R3F-specific, you could use it in a web worker to prepare a 3D noise texture. If you want to experiment with volumetric techniques without coding everything, look at Hydra or CableGL – these are creative coding tools for shaders that sometimes have ready-made cloud shader examples you can adapt.
	•	Debugging and Tuning: For shader debugging, Spector.js is invaluable – it can capture WebGL frames and show shader code and draw calls, helping optimize the cloud rendering. In R3F context, enabling renderer.debug.checkShaderErrors = true can assist during development. Additionally, use UI toolkits like Leva (React Leva) to create a control panel for cloud parameters (density, light color, etc.). Leva integrates nicely with R3F; you can live-tweak your shader uniforms (for example, noise scale, cloud coverage, phase function g-value) via sliders and color pickers. This kind of interactive tuning is often how the “perfect” golden-hour look is achieved – adjusting values until the clouds have just the right glow and softness.

Each of these resources and techniques will help you build a visually stunning, performant cloud hero scene. By combining careful shader work (for realism and softness) with React Three Fiber patterns (for scroll control and optimization), you can recreate that Cartier Journey ambiance: sailing through luminous golden clouds in a smooth, immersive web experience.

Sources: The implementation insights above draw from Three.js forum discussions ￼ ￼, open-source projects and tutorials ￼ ￼ ￼, and expert articles on volumetric rendering ￼ ￼. They reflect the state-of-the-art approaches as of 2025 for WebGL2 cloud rendering. Use these references as a springboard for deeper exploration and tweaking to achieve your desired result. Good luck with your sky-high hero section!